---
title: "S7-L2: Quiz 1"
description: "Shared Memory + Warp Divergence - Quiz 1の解説"
sectionNumber: 7
sectionTitle: "Shared Memory + Warp Divergence"
lectureNumber: 2
lectureTitle: "Quiz 1"
difficulty: "advanced"
tags: ["memory-optimization", "cuda"]
category: "memory-optimization"
order: 702
---

## 概要

このクイズでは，共有メモリ（Shared Memory）とワープダイバージェンス（Warp Divergence）に関する理解度を確認する．セクション7で学んだ内容を振り返りながら，各問題に取り組もう．

## クイズ

### Q1: 共有メモリのレイテンシ

共有メモリのアクセスレイテンシとして最も近い値はどれか？

- (a) 5サイクル
- (b) 20-25サイクル
- (c) 200サイクル
- (d) 300サイクル以上

<details>
<summary>解答を見る</summary>

正解: (b) 20-25サイクル

共有メモリはオンチップメモリであり，L1キャッシュ（32-33サイクル）よりも低いレイテンシでアクセスできる．L2キャッシュは約200サイクル，グローバルメモリは300サイクル以上のレイテンシとなる．

</details>

### Q2: 共有メモリとL1キャッシュの関係

A100 GPUにおける共有メモリとL1キャッシュの関係として正しいものはどれか？

- (a) 完全に独立した物理ユニットである
- (b) 同じ物理ユニット（合計192KB）を共有し，サイズ配分が設定可能である
- (c) 共有メモリはL1キャッシュの一部であり，分離できない
- (d) L1キャッシュのほうが共有メモリより高速である

<details>
<summary>解答を見る</summary>

正解: (b) 同じ物理ユニット（合計192KB）を共有し，サイズ配分が設定可能である

A100 GPUでは，共有メモリとL1キャッシュが1つの物理ユニット（192KB）を共有する．共有メモリは0KBから最大164KBまで設定可能で，残りがL1キャッシュに割り当てられる．共有メモリのほうがL1キャッシュより低レイテンシである．

</details>

### Q3: バンクコンフリクト

32スレッドのワープが，4バイト要素を16バイトストライドでアクセスした場合，バンクコンフリクトは何回発生するか？

- (a) 0回
- (b) 1回
- (c) 3回
- (d) 7回

<details>
<summary>解答を見る</summary>

正解: (c) 3回

16バイトストライドは4バンク間隔に相当する．32スレッドのアクセスが4つのキャッシュラインにまたがり，各バンク列に4つのアクセスが集中する．バンクコンフリクト数 = 最大アクセス数 - 1 = 4 - 1 = 3回となる．

</details>

### Q4: ワープダイバージェンスの影響

ワープダイバージェンスが発生した場合の動作として正しいものはどれか？

- (a) 異なるパスのスレッドが同時に並列実行される
- (b) ワープ全体が停止し，再スケジューリングされる
- (c) 異なるパスが直列化され，一方のパスのスレッドが待機状態になる
- (d) ダイバージェンスが発生したスレッドは自動的に終了する

<details>
<summary>解答を見る</summary>

正解: (c) 異なるパスが直列化され，一方のパスのスレッドが待機状態になる

ワープダイバージェンスが発生すると，GPUは異なる分岐パスを直列化して実行する．一方のパスを実行中，他方のスレッドはアイドル状態となり，スレッド利用率が低下する．

</details>

### Q5: ブロードキャスト

共有メモリにおいて，8スレッドが同一バンクの同一アドレスを読み込む場合，バンクコンフリクトは何回発生するか？

- (a) 7回
- (b) 4回
- (c) 1回
- (d) 0回

<details>
<summary>解答を見る</summary>

正解: (d) 0回

複数スレッドが同一バンクの同一アドレスを読み込む場合は「ブロードキャスト」として処理され，バンクコンフリクトは発生しない．コンフリクトが発生するのは，同一バンク（列）の異なるアドレス（異なる行）にアクセスする場合である．

</details>

### Q6: 共有メモリの宣言

CUDAコードで共有メモリを確保する方法として正しいものはどれか？

- (a) `__global__ float sharedArray[256];`
- (b) `__shared__ float sharedArray[256];`
- (c) `__device__ float sharedArray[256];`
- (d) `__cache__ float sharedArray[256];`

<details>
<summary>解答を見る</summary>

正解: (b) `__shared__ float sharedArray[256];`

`__shared__`修飾子を使用することで，共有メモリ上に変数を確保できる．`__global__`はカーネル関数の宣言に使用し，`__device__`はグローバルメモリ上のデバイス変数の宣言に使用する．

</details>

## まとめ

- 共有メモリはソフトウェア管理可能な低レイテンシメモリで，データの再利用時に有効
- バンクコンフリクトはアクセスパターンに依存し，ストライドの設計が重要
- ワープダイバージェンスは分岐による直列化を引き起こし，パフォーマンス低下の原因となる
