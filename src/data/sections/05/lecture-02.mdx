---
title: "S5-L2: Vector addition with a size not power of 2 !!! important"
description: "Performance analysis for the previous applications - Vector addition with a size not power of 2 !!! importantの解説"
sectionNumber: 5
sectionTitle: "Performance analysis for the previous applications"
lectureNumber: 2
lectureTitle: "Vector addition with a size not power of 2 !!! important"
difficulty: "intermediate"
tags: ["performance", "cuda"]
category: "performance"
order: 502
---

## 概要

CUDAプログラミングにおいて，ベクトルの要素数が32の倍数でない場合のスレッド利用効率と性能への影響を解説する．ワープサイズ（32スレッド）に合わないデータサイズでは一部のスレッドがアイドル状態となり，ブロック・グリッドの構成方法次第でスレッド利用率とウェーブ数が大きく変わることを具体例で示す．

## 主要な内容

### 32の倍数でない要素数の問題

CUDAアプリケーションの最小実行単位は1ワープ（32スレッド）である．要素数が32の倍数でない場合，最後のワープの一部のスレッドはアイドル状態となり利用されない．

例えばベクトルサイズが16要素の場合:
- 最小ワープサイズ32スレッドを割り当てる必要がある
- 16スレッドのみが実際に計算を行い，残り16スレッドはアイドル
- スレッド利用率は50%

これが，以前のアプリケーションで要素数を1024や2048（32の倍数）に設定していた理由である．

### ブロック構成の影響: 2つのシナリオ

1000要素のベクトル加算を例に，ブロック構成の違いによるスレッド利用率の変化を比較する．

```mermaid
flowchart TD
    subgraph "シナリオ1: 10ブロック x 100要素"
        A1[各ブロック: 4ワープ = 128スレッド] --> A2[使用: 100スレッド]
        A2 --> A3[アイドル: 28スレッド/ブロック]
        A3 --> A4[スレッド利用率: 78%]
    end
    subgraph "シナリオ2: 8ブロック x 128要素"
        B1[ブロック0-6: 4ワープ = 128スレッド全使用] --> B2[ブロック7: 128スレッド中104使用]
        B2 --> B3[アイドル: 24スレッド（最終ブロックのみ）]
        B3 --> B4[スレッド利用率: 96.6%]
    end
```

シナリオ1（10ブロック x 100要素）:
- 各ブロックは100要素を処理するが，ワープサイズの制約から128スレッド（4ワープ）が必要
- 3ワープは完全に利用されるが，4つ目のワープは4スレッドのみ使用
- 各ブロックで28スレッドがアイドル状態
- スレッド利用率: 100 / 128 = 78%

シナリオ2（8ブロック x 128要素）:
- 7つのブロックは128スレッドをすべて使用
- 最後のブロックのみ104スレッドを使用（24スレッドがアイドル）
- 平均スレッド利用率: 96.6%

### ウェーブ数への影響

ブロック数の違いはウェーブ数にも影響する．例えばGPUに8つのSMがある場合:

- シナリオ1（10ブロック）: 第1ウェーブで8ブロック実行，第2ウェーブで残り2ブロック → 2ウェーブ
- シナリオ2（8ブロック）: 第1ウェーブで8ブロック全て実行 → 1ウェーブ

ウェーブ数が減ることで実行時間を短縮できる．

### スレッドあたり複数要素の処理

各スレッドに複数の要素を処理させることで，総スレッド数とブロック数を削減できる．例えば1024要素で各スレッドが2要素を処理する場合，必要なスレッド数は512に半減し，ブロック数も減少する．これによりオキュパンシーが改善される場合がある．

### 最適なパラメータ選択

性能に影響する3つの設定値の関係:

- ベクトルの要素数（`N`）: アプリケーションの入力サイズ
- ブロックサイズ（`threadsPerBlock`）: ワープ数の倍数で選択
- グリッドサイズ（`blocksPerGrid`）: `(N + threadsPerBlock - 1) / threadsPerBlock`で計算

```cuda
int threadsPerBlock = 128;
int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, N);
```

カーネル内では境界チェックが必要である．

```cuda
__global__ void vectorAdd(int *a, int *b, int *c, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        c[i] = a[i] + b[i];
    }
}
```

## まとめ

- ベクトル要素数が32の倍数でない場合，最後のワープの一部スレッドがアイドル状態となりスレッド利用率が低下する
- ブロック構成の選択により，スレッド利用率が78%から96.6%まで大きく変化する
- ブロック数の違いはウェーブ数に影響し，ウェーブ数の削減は実行時間の短縮に直結する
- スレッドあたり複数要素を処理させることで，ブロック数を削減しオキュパンシーを改善できる可能性がある
- カーネル内の境界チェック（`if (i < n)`）は，余剰スレッドが不正なメモリアクセスを行わないために不可欠である
